# Tensorflow includes and defines
TF_INC=$(shell python -c 'from __future__ import print_function; import tensorflow as tf; print(tf.sysconfig.get_include())')
TF_LIB=$(shell python -c 'import tensorflow as tf; print(tf.sysconfig.get_lib())')
TF_CUDA=$(shell python -c 'from __future__ import print_function; import tensorflow as tf; print(int(tf.test.is_built_with_cuda()))')

TF_FLAGS=-D_MWAITXINTRIN_H_INCLUDED -D_FORCE_INLINES

# Dependencies
DEPDIR:=.d
$(shell mkdir -p $(DEPDIR) >/dev/null)
DEPFLAGS=-MT $@ -MMD -MP -MF $(DEPDIR)/$*.Td

# Define our sources, compiling CUDA code if it's enabled
ifeq ($(TF_CUDA), 1)
    SOURCES=$(wildcard *.cpp *.cu)
else
    SOURCES=$(wildcard *.cpp)
endif

# Define objects and shared_library
OBJECTS=$(addsuffix .o, $(basename $(SOURCES)))
LIBRARY={{shared_library}}

# Compiler flags
INCLUDES= -I $(TF_INC) -I$(TF_INC)/external/nsync/public
CPPFLAGS=-std=c++11 $(TF_FLAGS) $(INCLUDES) -fPIC -fopenmp -O2 -march=native -mtune=native
NVCCFLAGS=-std=c++11 -D GOOGLE_CUDA=$(TF_CUDA) $(TF_FLAGS) $(INCLUDES) \
	-x cu --compiler-options "-fPIC" --gpu-architecture=sm_30 -lineinfo

LDFLAGS = -fPIC -fopenmp -L$(TF_LIB) -ltensorflow_framework{{extra_libs}}

# Compiler directives
COMPILE.cpp = g++ $(DEPFLAGS) $(CPPFLAGS) -c
COMPILE.nvcc = nvcc --compiler-options " $(DEPFLAGS)" $(NVCCFLAGS) -c

all : $(LIBRARY)

%.o : %.cpp
	$(COMPILE.cpp) $<

%.o : %.cu
	$(COMPILE.nvcc) $<

clean :
	rm -f $(OBJECTS) $(LIBRARY)

install :
	cp $(LIBRARY) $(TF_LIB)

$(LIBRARY) : $(OBJECTS)
	g++  -shared $(OBJECTS) -o $(LIBRARY) $(LDFLAGS)

$(DEPDIR)/%.d: ;
.PRECIOUS: $(DEPDIR)/%.d

-include $(patsubst %,$(DEPDIR)/%.d,$(basename $(SRCS)))